{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#библиотеки \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159566</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159567</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159568</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159569</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159570</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159566  \":::::And for the second time of asking, when ...      0\n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159569  And it looks like it was actually you who put ...      0\n",
       "159570  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159571 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9e7d1fc4d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['toxic'].value_counts().plot(kind = 'pie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "toxic    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные открыты и изучены. \n",
    "\n",
    "Таблица состоит из двух столбцов. \n",
    "\n",
    "Всего исслелований в выборочных данных - 159571.\n",
    "\n",
    "Пропуски и дубликаты в данных отсутствуют. \n",
    "\n",
    "Наибольшая часть комментариев (90%) имеют положительный контекст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z ]', ' ', text)\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "clean_questions= []\n",
    "for question in data['text']: \n",
    "    clean_questions.append(clean_text(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting textblob\n",
      "  Downloading textblob-0.15.3-py2.py3-none-any.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 767 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nltk>=3.1 in /opt/conda/lib/python3.7/site-packages (from textblob) (3.4.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk>=3.1->textblob) (1.15.0)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.15.3\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n",
    "from textblob import TextBlob, Word\n",
    "\n",
    "lemm_text = []\n",
    "for lemm in clean_questions:\n",
    "    lemm_text.append(TextBlob(lemm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D aww He matches this background colour I m seemingly stuck with Thanks talk January UTC'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TextBlob(\"D aww He matches this background colour I m seemingly stuck with Thanks talk January UTC\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(clean_questions[1], lemm_text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['toxic']\n",
    "features = pd.Series(lemm_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train,features_test,target_train,target_test = train_test_split(features,target,test_size = 0.2,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#уменьшение выборки \n",
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "    \n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345)\n",
    "    \n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "#применение функции\n",
    "features_train,target_train = downsample(features_train,target_train,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    57338\n",
       "1    12981\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Оценка важности слова в тексте\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "\n",
    "features_train = features_train.astype('U')\n",
    "features_test = features_test.astype('U')\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords,use_idf=True)\n",
    "\n",
    "features_train = vectorizer.fit_transform(features_train)\n",
    "\n",
    "vectorizer.get_stop_words()\n",
    "\n",
    "features_test = vectorizer.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9225102746057253 8\n"
     ]
    }
   ],
   "source": [
    "#выбор значения гиперпараметра max_iter для модели № 1\n",
    "max_iter_array = [1, 3, 5,6,7,8,9,10,20,25,30,35,40,45,50,55,60,65,70,75,80,90,100]\n",
    "model = LogisticRegression()\n",
    "grid = GridSearchCV(model, param_grid={'max_iter': max_iter_array})\n",
    "grid.fit(features_train,target_train)\n",
    "\n",
    "best_max_iter = grid.best_estimator_.max_iter\n",
    "print(grid.best_score_, best_max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7611139941186645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter =8,random_state = 42)\n",
    "model.fit(features_train,target_train)\n",
    "pred = model.predict(features_test)\n",
    "print(f1_score(target_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#выбор гиперпараметров для модели №2\n",
    "n_estimators_array = [1, 3, 5, 7, 10, 15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100]\n",
    "max_depth_array = [1, 3, 5, 7, 10, 15,20,25]\n",
    "model_2 = RandomForestClassifier(random_state = 42)\n",
    "grid = GridSearchCV(model_2, param_grid={'n_estimators': n_estimators_array,'max_depth': max_depth_array})\n",
    "grid.fit(features_train,target_train)\n",
    "best_n_estimators = grid.best_estimator_.n_estimators\n",
    "best_max_depth = grid.best_estimator_.max_depth\n",
    "print(grid.best_score_, best_n_estimators,best_max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 11, 21, 31, 41, 51, 61, 71, 81, 91, 101]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1, 4, 7, 10, 13, 16, 19, 22]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_estim = list(range(1, 102, 10)) #От 1 до 102 с шагом 10\n",
    "depth = list(range(1, 25, 3))\n",
    "display(n_estim, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2777777777777778\n"
     ]
    }
   ],
   "source": [
    "#случайный лес \n",
    "model2 = RandomForestClassifier(random_state = 42,n_estimators=1,max_depth = 25)\n",
    "model2.fit(features_train,target_train)\n",
    "pred2 = model2.predict(features_test)\n",
    "print(f1_score(target_test,pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#выбор значения гиперпараметра max_depth для модели № 3\n",
    "max_depth_array = [1, 3, 5,6, 7, 10, 15,20,25]\n",
    "model_3 = DecisionTreeClassifier()\n",
    "grid = GridSearchCV(model_3, param_grid={'max_depth': max_depth_array})\n",
    "grid.fit(features_train,target_train)\n",
    "best_max_depth = grid.best_estimator_.max_depth\n",
    "print(grid.best_score_, best_max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6659217877094973\n"
     ]
    }
   ],
   "source": [
    "#модель №3\n",
    "model3 = DecisionTreeClassifier(random_state = 42,max_depth = 25)\n",
    "model3.fit(features_train,target_train)\n",
    "pred3 = model3.predict(features_test)\n",
    "print(f1_score(target_test, pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Комментарий наставника\n",
    "<span style=\"color:green\">Отлично, к модели дерева решений нечего добавить.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждой модели были выбраны оптимальные гперпараметры, и подсчитана доля правильных ответов.\n",
    "\n",
    "Качество модели № 1 показало наилучший результат со исследуемой метрике.\n",
    "\n",
    "<font color = blue>\n",
    "F1-мера модели № 1:0.76111\n",
    "</font>\n",
    "\n",
    "F1-мера модели № 2:0.27777\n",
    "\n",
    "F1-мера модели № 3: 0.66592\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка модели на адекватность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1346112427309929\n"
     ]
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier()\n",
    "dummy_clf.fit(features_train,target_train)\n",
    "pred_check = dummy_clf.predict(features_test)\n",
    "print(f1_score(target_test, pred_check))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки модели на адекватность был использован классификатор в качестве простой базовой линии для сравнения с реальными классификаторами. Проверка показала, что модель № 1  дает большую долю правильных ответов, чем используемым для сравнения классификатор, тем самым доказывая адекватность модели.\n",
    "\n",
    "F1-мера модели № 1: 0.76111\n",
    "\n",
    "F1-мера дамми-модели: 0.1284623"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные открыты и изучены. Таблица состоит из двух столбцов. Всего исслелований в выборочных данных - 159571.Пропуски и дубликаты в данных отсутствуют. Наибольшая часть комментариев (90%) имеют положительный контекст.\n",
    "\n",
    "Для каждой модели были выбраны оптимальные гперпараметры, и подсчитана доля правильных ответов.\n",
    "\n",
    "Качество модели № 1 показало наилучший результат со исследуемой метрике.\n",
    "\n",
    "<font color = blue>\n",
    "F1-мера модели № 1:0.76111\n",
    "</font>\n",
    "\n",
    "F1-мера модели № 2:0.27777\n",
    "\n",
    "F1-мера модели № 3: 0.66592\n",
    "\n",
    "\n",
    "Для проверки модели на адекватность был использован классификатор в качестве простой базовой линии для сравнения с реальными классификаторами. Проверка показала, что модель № 1  дает большую долю правильных ответов, чем используемым для сравнения классификатор, тем самым доказывая адекватность модели.\n",
    "\n",
    "F1-мера модели № 1: 0.76111\n",
    "\n",
    "F1-мера дамми-модели: 0.1284623"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
